#!/bin/bash
#SBATCH -J logs/yearbook10_densenet_5_epochs_32_cc           # job namu
#SBATCH -o logs/yearbook10_densenet_5_epochs_32_cc.o%j       # output and error file name (%j expands to jobID)
#SBATCH -n 1 -N 1               # total number of mpi tasks requested
#SBATCH -p gpu     # queue (partition) -- normal, development, etc.
#SBATCH -t 12:00:00        # run time (hh:mm:ss) - 1.5 hours
#SBATCH --mail-user=pandian@cs.utexas.edu
#SBATCH --mail-type=begin  # email me when the job starts
#SBATCH --mail-type=end    # email me when the job finishes

run=10
# Make sure to change the job name and output log file name in the above SBATCH directives
architecture='alexnet'

# Whether to continue from previously saved model (you might want to change initial_epoch also)
continue_previous_run=0
initial_epoch=0

checkpoint='checkpoint'$run'.h5'
use_pretraining=1
fine_tuning='freeze-initial'

# Training parameters
batch_size=32
num_epochs=5
optimizer='sgd'
loss='categorical_crossentropy'

echo '--------------------------------- SBATCH SCRIPT -------------------------------------'
cat ./sbatch_script
echo '-------------------------------------------------------------------------------------'

./run.sh --DATASET_TYPE=yearbook --type=valid --model_architecture=$architecture --load_saved_model=$continue_previous_run --checkpoint_file_name=$checkpoint --use_pretraining=$use_pretraining --fine_tuning_method=$fine_tuning --batch_size=$batch_size --num_epochs=$num_epochs --loss=$loss --optimizer=$optimizer --initial_epoch=$initial_epoch